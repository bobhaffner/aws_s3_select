{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:32:34.131302Z",
     "start_time": "2018-09-07T02:32:33.409297Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T03:38:20.469982Z",
     "start_time": "2018-09-07T03:38:18.702545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832\n",
      "   Duration       Start Date       Start Station\n",
      "0       409  8/31/2015 23:10  San Jose City Hall\n",
      "1      2915  8/30/2015 22:32  San Jose City Hall\n",
      "2      2915  8/30/2015 22:31  San Jose City Hall\n",
      "3       447  8/28/2015 15:31  San Jose City Hall\n",
      "4       756  8/27/2015 13:06  San Jose City Hall\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'my-bucket'\n",
    "file_name = '201508_trip_data.csv'\n",
    "\n",
    "\n",
    "sql_stmt = \"SELECT * FROM s3object s WHERE s.\\\"Start Station\\\" = 'San Jose City Hall'\"\n",
    "\n",
    "\n",
    "# making the request\n",
    "req = s3.select_object_content(\n",
    "    Bucket=bucket_name,\n",
    "    Key=file_name,\n",
    "    ExpressionType='SQL',\n",
    "    Expression=sql_stmt,\n",
    "    InputSerialization = {'CSV': {'FileHeaderInfo': 'Use'}},\n",
    "    OutputSerialization = {'CSV': {}},\n",
    ")\n",
    "\n",
    "records = []\n",
    "\n",
    "# looping through the payload of the AWS EventStream and getting one or more Records and Stats\n",
    "for event in req['Payload']:\n",
    "    if 'Records' in event:\n",
    "        records.append(event['Records']['Payload'])\n",
    "    elif 'Stats' in event:\n",
    "        stats = event['Stats']['Details']\n",
    "\n",
    "\n",
    "# converting the byte strings to strings and then joining them together to form one large string\n",
    "file_str = ''.join(r.decode('utf-8') for r in records)\n",
    "\n",
    "# doing StringIO(file_str) so it looks like CSV file to pd.read_csv()\n",
    "select_df = pd.read_csv(StringIO(file_str), usecols=[1,2,3], names=['Duration', 'Start Date', 'Start Station'])\n",
    "print(len(select_df))\n",
    "print(select_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T02:49:23.870935Z",
     "start_time": "2018-09-07T02:49:23.866637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BytesScanned': 43012650, 'BytesProcessed': 43012650, 'BytesReturned': 94037}\n"
     ]
    }
   ],
   "source": [
    "print (stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T03:40:15.201633Z",
     "start_time": "2018-09-07T03:40:05.570637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "832\n"
     ]
    }
   ],
   "source": [
    "# reading the entire file from S3\n",
    "df = pd.read_csv('s3://my-bucket/201508_trip_data.csv', usecols=[1,2,3])\n",
    "\n",
    "# filtering for stations marked as San Jose City Hall\n",
    "filter = df['Start Station'] == 'San Jose City Hall'\n",
    "print(len(df[filter]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-04T03:06:27.679671Z",
     "start_time": "2018-09-04T03:06:27.656675Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_s3_csv(s3_client, bucket_name, file_name, sql_stmt):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    s3_client : botocore.client.S3\n",
    "    bucket_name : str, name of the S3 bucket\n",
    "    file_name : str, name of the CSV file\n",
    "    sql_stmt : str, sql statement\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    records : list of byte strings, contents of the CSV file minus column headers\n",
    "    stats : dict, stat details from the EventStream\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    # making the request\n",
    "    req = s3_client.select_object_content(\n",
    "        Bucket=bucket_name,\n",
    "        Key=file_name,\n",
    "        ExpressionType='SQL',\n",
    "        Expression=sql_stmt,\n",
    "        InputSerialization = {'CSV': {'FileHeaderInfo': 'Use'}},\n",
    "        OutputSerialization = {'CSV': {}},\n",
    "    )\n",
    "    \n",
    "    records = []\n",
    "    \n",
    "    # looping through the payload of the AWS EventStream and getting one or more Records and Stats\n",
    "    for event in req['Payload']:\n",
    "        if 'Records' in event:\n",
    "            records.append(event['Records']['Payload'])\n",
    "        elif 'Stats' in event:\n",
    "            stats = event['Stats']['Details']\n",
    "            \n",
    "    return records, stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev35]",
   "language": "python",
   "name": "conda-env-dev35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
